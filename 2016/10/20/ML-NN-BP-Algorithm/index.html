<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <title>反向传播算法从理论到实践 | Kinthon</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="参考出处
把参考出处放于这里，是强烈推荐大家去阅读以下的链接，作者写的十分清晰而有逻辑
http://neuralnetworksanddeeplearning.com/chap2.html


本文只是针对上述文章进行总结和增加一些东西方便理解

简述
什么是反向传播算法
我们知道在深度学习的发展历史中，多层感知机提出后，虽然解决了异或问题，但是由于其复杂的计算量问题，从而导致了其研究受阻，之后">
<meta property="og:type" content="article">
<meta property="og:title" content="反向传播算法从理论到实践">
<meta property="og:url" content="https://sysukinthon.github.io/2016/10/20/ML-NN-BP-Algorithm/index.html">
<meta property="og:site_name" content="Kinthon">
<meta property="og:description" content="参考出处
把参考出处放于这里，是强烈推荐大家去阅读以下的链接，作者写的十分清晰而有逻辑
http://neuralnetworksanddeeplearning.com/chap2.html


本文只是针对上述文章进行总结和增加一些东西方便理解

简述
什么是反向传播算法
我们知道在深度学习的发展历史中，多层感知机提出后，虽然解决了异或问题，但是由于其复杂的计算量问题，从而导致了其研究受阻，之后">
<meta property="og:image" content="http://7xncgn.com1.z0.glb.clouddn.com/public/16-11-17/32649134.jpg">
<meta property="og:updated_time" content="2016-11-17T10:37:32.777Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="反向传播算法从理论到实践">
<meta name="twitter:description" content="参考出处
把参考出处放于这里，是强烈推荐大家去阅读以下的链接，作者写的十分清晰而有逻辑
http://neuralnetworksanddeeplearning.com/chap2.html


本文只是针对上述文章进行总结和增加一些东西方便理解

简述
什么是反向传播算法
我们知道在深度学习的发展历史中，多层感知机提出后，虽然解决了异或问题，但是由于其复杂的计算量问题，从而导致了其研究受阻，之后">
  
    <link rel="alternative" href="/atom.xml" title="Kinthon" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css" type="text/css">
<link rel="canonical" href="https://sysukinthon.github.io/2016/10/20/ML-NN-BP-Algorithm/">
<script type="text/javascript">
       var host = "sysukinthon.github.io";
       if ((host == window.location.host) && (window.location.protocol != "https:"))
           window.location.protocol = "https";
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="/img/avatar.jpg" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">Kinthon</a></h1>
		</hgroup>

		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						
						<li>关于我</li>
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives">所有文章</a></li>
				        
							<li><a href="/tags/Web">前端</a></li>
				        
							<li><a href="/tags/CG">计算机图形学</a></li>
				        
							<li><a href="/tags/ML">机器学习</a></li>
				        
							<li><a href="/tags/NN">神经网络</a></li>
				        
							<li><a href="/tags/Others">其他</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/sysuKinthon" title="github">github</a>
					        
								<a class="douban" target="_blank" href="http://www.cnblogs.com/kinthon/" title="douban">douban</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/Browser/" style="font-size: 10px;">Browser</a> <a href="/tags/CG/" style="font-size: 13.33px;">CG</a> <a href="/tags/CSS/" style="font-size: 10px;">CSS</a> <a href="/tags/DL/" style="font-size: 11.67px;">DL</a> <a href="/tags/HTML/" style="font-size: 10px;">HTML</a> <a href="/tags/JS/" style="font-size: 10px;">JS</a> <a href="/tags/ML/" style="font-size: 16.67px;">ML</a> <a href="/tags/Math/" style="font-size: 10px;">Math</a> <a href="/tags/NN/" style="font-size: 10px;">NN</a> <a href="/tags/Node/" style="font-size: 15px;">Node</a> <a href="/tags/OpenGL/" style="font-size: 11.67px;">OpenGL</a> <a href="/tags/OpengGL/" style="font-size: 10px;">OpengGL</a> <a href="/tags/Opengl/" style="font-size: 10px;">Opengl</a> <a href="/tags/Others/" style="font-size: 18.33px;">Others</a> <a href="/tags/Project/" style="font-size: 13.33px;">Project</a> <a href="/tags/Security/" style="font-size: 10px;">Security</a> <a href="/tags/Web/" style="font-size: 20px;">Web</a> <a href="/tags/基础知识/" style="font-size: 11.67px;">基础知识</a>
					</div>
				</section>
				
				
				

				
				
				<section class="switch-part switch-part3">
				
					<div id="js-aboutme">灵魂之于菩堤，清则静； 追求之于世俗，强则存。</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">Kinthon</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
			
				<img lazy-src="/img/avatar.jpg" class="js-avatar">
			
			</div>
			<hgroup>
			  <h1 class="header-author">Kinthon</h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives">所有文章</a></li>
		        
					<li><a href="/tags/Web">前端</a></li>
		        
					<li><a href="/tags/CG">计算机图形学</a></li>
		        
					<li><a href="/tags/ML">机器学习</a></li>
		        
					<li><a href="/tags/NN">神经网络</a></li>
		        
					<li><a href="/tags/Others">其他</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/sysuKinthon" title="github">github</a>
			        
						<a class="douban" target="_blank" href="http://www.cnblogs.com/kinthon/" title="douban">douban</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>

      <div class="body-wrap"><article id="post-ML-NN-BP-Algorithm" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/10/20/ML-NN-BP-Algorithm/" class="article-date">
  	<time datetime="2016-10-20T01:38:53.000Z" itemprop="datePublished">2016-10-20</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      反向传播算法从理论到实践
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ML/">ML</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/NN/">NN</a></li></ul>
	</div>

        

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <h3 id="参考出处"><a href="#参考出处" class="headerlink" title="参考出处"></a>参考出处</h3><ul>
<li>把参考出处放于这里，是强烈推荐大家去阅读以下的链接，作者写的十分清晰而有逻辑<ul>
<li><a href="http://neuralnetworksanddeeplearning.com/chap2.html" target="_blank" rel="external">http://neuralnetworksanddeeplearning.com/chap2.html</a></li>
</ul>
</li>
<li>本文只是针对上述文章进行总结和增加一些东西方便理解</li>
</ul>
<h3 id="简述"><a href="#简述" class="headerlink" title="简述"></a>简述</h3><ul>
<li>什么是反向传播算法<ul>
<li>我们知道在深度学习的发展历史中，多层感知机提出后，虽然解决了异或问题，但是由于其复杂的计算量问题，从而导致了其研究受阻，之后有学者提出了反向传播的算法，解决了神经网络所需要的复杂计算量问题，从而带动了业界使用多层感知机研究的热潮；所以其实反向传播算法是用于在多层神经网络中训练出我们神经网络中的参数的快速算法；</li>
</ul>
</li>
<li>算法的目的<ul>
<li>我们知道在进行模型调优的时候，我们是使用梯度下降的方式，或是其变种，而反向传播算法本身主要是通过计算出损失函数梯度向量</li>
</ul>
</li>
</ul>
<h3 id="算法"><a href="#算法" class="headerlink" title="算法"></a>算法</h3><h4 id="符号给定"><a href="#符号给定" class="headerlink" title="符号给定"></a>符号给定</h4><ul>
<li>$z^l$:代表了l层的所有神经元的加权和组成的数组(向量)，也就是上一层的输出值与本层的权重的加权和加上偏置; $z^l=w^la^{l-1} + b^l$</li>
<li>$z^l_j$:代表了l层的第j个神经元的加权和，$z^l_j=w^l_ja^{l-1} + b^l$</li>
<li>$a^l$:代表了l层的激活值，也就是l层的输出，l+1层的输入; $a^l = \sigma{z^l}$</li>
<li>$w^l$:代表了l层的权重向量矩阵;</li>
<li>$w^l_j$：代表了l层的第j个神经元的权重向量</li>
<li>$w^l_{jk}$:代表了第l层中第j个神经元里面从l-1层第k个神经元指过来的权重，是个标量</li>
<li>$b^l$:代表了l层的所有神经元的偏置组成的向量</li>
<li>$b^l_j$:代表了l层第j个神经元的偏置,是个标量</li>
<li>$\sigma$:激活函数</li>
<li>$C$:损失函数，$C=\frac{1}{2n}||y(x) - a^L(x)||^2$</li>
<li>$\delta^L$:L层的误差；$\delta^l_j=\frac{\partial C}{\partial z^l_j}$<ul>
<li>这里要对这个误差进行一些说明，也正是这个中间变量，误差的引入，才使得我们算法得以实现；</li>
<li>这个误差从定义上来看就是我们的误差函数对于每层的每一个输出去求一个偏导，我们知道偏导这个东西就代表了变化率；那么这个误差其实就代表了我们的神经元的输出对于这个损失有多大的影响，如果这个值越接近0的话，就代表了我们的这个神经元其实对这个损失并没有多大贡献，这也正是我们所希望达到的整体效果</li>
</ul>
</li>
</ul>
<h4 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h4><ul>
<li>明确目的：我们要求的是<ul>
<li>$\frac{\partial C}{\partial w^l_{jk}}$</li>
<li>$\frac{\partial C}{\partial b^l_j}$</li>
</ul>
</li>
<li>输入x:设输入层的激活值为$a^1$，一般激活值就是输入值；因为输入层的神经元一般没有计算单元（$a^1 == x$）</li>
<li>前向传播：对于每一个l=2,3,…,L，计算出$z^l=w^la^{l-1} + b^l,a^l=\sigma(z^l)$</li>
<li>计算输出层的误差向量，$\delta^{L} = \nabla_a C \odot \sigma’(z^L)$; 其中$\nabla_a C$代表了C对a求偏导；$\odot$是执行对应元素相乘；比如<script type="math/tex">\begin{eqnarray}
\left[\begin{array}{c} 1 \\ 2 \end{array}\right] 
\odot \left[\begin{array}{c} 3 \\ 4\end{array} \right]
= \left[ \begin{array}{c} 1 * 3 \\ 2 * 4 \end{array} \right]
= \left[ \begin{array}{c} 3 \\ 8 \end{array} \right].
\tag{28}\end{eqnarray}</script></li>
<li>反向传播误差：对于每一个l=L-1,L-2，…, 2，计算出$\delta^{l} = ((w^{l+1})^T \delta^{l+1}) \odot \sigma’(z^{l})$</li>
<li>得到损失函数的梯度<ul>
<li>$\frac{\partial C}{\partial w^l_{jk}} = a^{l-1}_k \delta^l_j$</li>
<li>$\frac{\partial C}{\partial b^l_j} = \delta^l_j$</li>
</ul>
</li>
</ul>
<h3 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h3><h4 id="预备理论"><a href="#预备理论" class="headerlink" title="预备理论"></a>预备理论</h4><ul>
<li>导数链式法则，也叫多元复合的求导法则<ul>
<li>设$y=f(u<em>1,u_2,…,u_m)$可微，$u_i=u_i(t) (i=1,2,…,m)$可导，则有$\frac {dy}{dt} = \sum^m</em>{i=1}<br>\frac {\partial y}{\partial u_i} \frac {du_i}{dt}$</li>
</ul>
</li>
</ul>
<h4 id="四大公式"><a href="#四大公式" class="headerlink" title="四大公式"></a>四大公式</h4><ul>
<li><img src="http://7xncgn.com1.z0.glb.clouddn.com/public/16-11-17/32649134.jpg" alt="上图"></li>
<li>接下来我们针对上述的公式利用多元复合函数求导法则进行证明</li>
<li>首先，把一些相关的公式放在这里<ul>
<li>$C=\frac{1}{2n}||y(x) - a^L(x)||^2$</li>
<li>$a^l=\sigma(z^l)$</li>
</ul>
</li>
<li>第一个是输出层的误差$\delta^L_j $,首先从定义出发，<script type="math/tex">\delta^L_j = \frac{\partial C}{\partial z^L_j}</script>，根据我们的导数链式法则，我们可以将还有我们关于损失函数的定义式，假设我们的输出有m+1个，则可以知道损失函数其实是$C=f(a^L_0,a^L_1,…,a^L_m)$的，所以由链式法则我们可以得到<script type="math/tex">\delta^L_j = \sum_k \frac{\partial C}{\partial a^L_k} \frac{\partial a^L_k}{\partial z^L_j}</script>但我们注意到，其实只有$a^L_j$与我们的$z^L_j$是有关系的，也就是$a^L_j = \sigma(z^L_j)$，而其余的是没有关系，也就是求导之后为0；则我们的公式可以写如下<script type="math/tex">\delta^L_j = \frac{\partial C}{\partial a^L_j} \frac{\partial a^L_j}{\partial z^L_j}</script>也就是<script type="math/tex">\delta^L_j = \frac{\partial C}{\partial a^L_j} \sigma'(z^L_j)</script></li>
<li>接下来证明非输出层的误差，也就是$\delta^l<em>j$，这里我们首先要明白一个，我们的输出$a^L$其实是前面所有输出的$a^l$的组合，也就是它们之间也是有函数关系的，也就是$z^l=w^la^{l−1}+b^l, a^l=\sigma(z^l),$；所以在l+1层中，我们的损失函数可以表示为$C=f(z^{l+1}_0,z^{l+1}_1,…,z^{l+1}_m)$的，而同时我们知道所以的a^{l+1}的数，都是$z^l_j$的函数，因为$z^l_j$是l+1层的输入之一；根据多元函数的求导法则我们可以得到<script type="math/tex">\begin{eqnarray}
\delta^l_j & = & \frac{\partial C}{\partial z^l_j} \\
& = & \sum_k \frac{\partial C}{\partial z^{l+1}_k} \frac{\partial z^{l+1}_k}{\partial z^l_j}\\ 
& = & \sum_k \frac{\partial z^{l+1}_k}{\partial z^l_j} \delta^{l+1}_k\end{eqnarray}</script> 关于$z^{l+1}_k与z^{l}_j$的关系，我们有$$z^{l+1}_k = \sum_j w^{l+1}</em>{kj} a^l<em>j +b^{l+1}_k = \sum_j w^{l+1}</em>{kj} \sigma(z^l<em>j) +b^{l+1}_k <script type="math/tex">对两边进行求导，我们可以得到</script>  \frac{\partial z^{l+1}_k}{\partial z^l_j} = w^{l+1}</em>{kj} \sigma’(z^l<em>j)<script type="math/tex">, 所以最后我们得到的结果为</script>  \delta^l_j = \sum_k w^{l+1}</em>{kj}  \delta^{l+1}_k \sigma’(z^l_j).$$</li>
<li>再接下来的两个的证明过程也是类似的，都是先设定损失函数的形式，再去进行链式求导</li>
</ul>
<h3 id="代码参考"><a href="#代码参考" class="headerlink" title="代码参考"></a>代码参考</h3><ul>
<li>以下是项目作者是github地址，代码写得相当清晰<a href="https://github.com/mnielsen/neural-networks-and-deep-learning" target="_blank" rel="external">mnielsen</a></li>
<li>运行,参照：<a href="http://neuralnetworksanddeeplearning.com/chap1.html#implementing_our_network_to_classify_digits" target="_blank" rel="external">mnielsen</a></li>
</ul>

      
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2016/10/21/Math-LinearAlgebra-matrix-fractorization/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption"><</strong>
      <div class="article-nav-title">
        
          线性代数之矩阵分解
        
      </div>
    </a>
  
  
    <a href="/2016/10/20/ML-gradient-relative/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">机器学习之梯度与相关算法</div>
      <strong class="article-nav-caption">></strong>
    </a>
  
</nav>

  
</article>


<div class="share_jia">
	<!-- JiaThis Button BEGIN -->
	<div class="jiathis_style">
		<span class="jiathis_txt">分享到: &nbsp; </span>
		<a class="jiathis_button_facebook"></a> 
    <a class="jiathis_button_twitter"></a>
    <a class="jiathis_button_plus"></a> 
    <a class="jiathis_button_tsina"></a>
		<a class="jiathis_button_cqq"></a>
		<a class="jiathis_button_douban"></a>
		<a class="jiathis_button_weixin"></a>
		<a class="jiathis_button_tumblr"></a>
    <a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	</div>
	<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=1405949716054953" charset="utf-8"></script>
	<!-- JiaThis Button END -->
</div>






<div class="duoshuo">
	<!-- 多说评论框 start -->
	<div class="ds-thread" data-thread-key="ML-NN-BP-Algorithm" data-title="反向传播算法从理论到实践" data-url="https://sysukinthon.github.io/2016/10/20/ML-NN-BP-Algorithm/"></div>
	<!-- 多说评论框 end -->
	<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"true"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
	<!-- 多说公共JS代码 end -->
</div>




</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2016 Kinthon
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="https://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js" type="text/javascript"></script>
<script src="/js/main.js" type="text/javascript"></script>






<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>