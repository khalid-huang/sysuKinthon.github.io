<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <title>机器学习算法之朴素贝叶斯算法 | Kinthon</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="以下是在学习《机器学习实战》时的一些记录

理论基础
朴素贝叶斯基于的两个理论基础
贝叶斯决策理论，也就是说如果我们对于一个（x,y）有两个概率,p1(x,y),p2(x,y)，分别代表了(x,y)是属于第1类或是第2类的概率，如果我们有p1(x,y) &amp;gt; p2(x,y)，那么我们就有信心将(x,y)归入到第1类中，反之就是归入第二类中
我们设定每个特征之间都是相互独立的，也就是说x,y之间">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习算法之朴素贝叶斯算法">
<meta property="og:url" content="https://sysukinthon.github.io/2016/10/24/ML-practice-bayes/index.html">
<meta property="og:site_name" content="Kinthon">
<meta property="og:description" content="以下是在学习《机器学习实战》时的一些记录

理论基础
朴素贝叶斯基于的两个理论基础
贝叶斯决策理论，也就是说如果我们对于一个（x,y）有两个概率,p1(x,y),p2(x,y)，分别代表了(x,y)是属于第1类或是第2类的概率，如果我们有p1(x,y) &amp;gt; p2(x,y)，那么我们就有信心将(x,y)归入到第1类中，反之就是归入第二类中
我们设定每个特征之间都是相互独立的，也就是说x,y之间">
<meta property="og:updated_time" content="2016-11-06T12:23:35.181Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="机器学习算法之朴素贝叶斯算法">
<meta name="twitter:description" content="以下是在学习《机器学习实战》时的一些记录

理论基础
朴素贝叶斯基于的两个理论基础
贝叶斯决策理论，也就是说如果我们对于一个（x,y）有两个概率,p1(x,y),p2(x,y)，分别代表了(x,y)是属于第1类或是第2类的概率，如果我们有p1(x,y) &amp;gt; p2(x,y)，那么我们就有信心将(x,y)归入到第1类中，反之就是归入第二类中
我们设定每个特征之间都是相互独立的，也就是说x,y之间">
  
    <link rel="alternative" href="/atom.xml" title="Kinthon" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css" type="text/css">
<link rel="canonical" href="https://sysukinthon.github.io/2016/10/24/ML-practice-bayes/">
<script type="text/javascript">
       var host = "sysukinthon.github.io";
       if ((host == window.location.host) && (window.location.protocol != "https:"))
           window.location.protocol = "https";
</script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img lazy-src="/img/avatar.jpg" class="js-avatar">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">Kinthon</a></h1>
		</hgroup>

		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>标签</li>
						
						
						<li>关于我</li>
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives">所有文章</a></li>
				        
							<li><a href="/tags/Web">前端</a></li>
				        
							<li><a href="/tags/CG">计算机图形学</a></li>
				        
							<li><a href="/tags/ML">机器学习</a></li>
				        
							<li><a href="/tags/NN">神经网络</a></li>
				        
							<li><a href="/tags/Others">其他</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="https://github.com/sysuKinthon" title="github">github</a>
					        
								<a class="douban" target="_blank" href="http://www.cnblogs.com/kinthon/" title="douban">douban</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/Browser/" style="font-size: 10px;">Browser</a> <a href="/tags/CG/" style="font-size: 14px;">CG</a> <a href="/tags/CSS/" style="font-size: 10px;">CSS</a> <a href="/tags/DL/" style="font-size: 12px;">DL</a> <a href="/tags/HTML/" style="font-size: 10px;">HTML</a> <a href="/tags/JS/" style="font-size: 10px;">JS</a> <a href="/tags/ML/" style="font-size: 18px;">ML</a> <a href="/tags/Math/" style="font-size: 10px;">Math</a> <a href="/tags/NN/" style="font-size: 10px;">NN</a> <a href="/tags/Node/" style="font-size: 16px;">Node</a> <a href="/tags/OpenGL/" style="font-size: 12px;">OpenGL</a> <a href="/tags/OpengGL/" style="font-size: 10px;">OpengGL</a> <a href="/tags/Opengl/" style="font-size: 10px;">Opengl</a> <a href="/tags/Others/" style="font-size: 18px;">Others</a> <a href="/tags/Project/" style="font-size: 14px;">Project</a> <a href="/tags/Security/" style="font-size: 10px;">Security</a> <a href="/tags/Web/" style="font-size: 20px;">Web</a> <a href="/tags/基础知识/" style="font-size: 12px;">基础知识</a>
					</div>
				</section>
				
				
				

				
				
				<section class="switch-part switch-part3">
				
					<div id="js-aboutme">灵魂之于菩堤，清则静； 追求之于世俗，强则存。</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">Kinthon</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
			
				<img lazy-src="/img/avatar.jpg" class="js-avatar">
			
			</div>
			<hgroup>
			  <h1 class="header-author">Kinthon</h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives">所有文章</a></li>
		        
					<li><a href="/tags/Web">前端</a></li>
		        
					<li><a href="/tags/CG">计算机图形学</a></li>
		        
					<li><a href="/tags/ML">机器学习</a></li>
		        
					<li><a href="/tags/NN">神经网络</a></li>
		        
					<li><a href="/tags/Others">其他</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/sysuKinthon" title="github">github</a>
			        
						<a class="douban" target="_blank" href="http://www.cnblogs.com/kinthon/" title="douban">douban</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>

      <div class="body-wrap"><article id="post-ML-practice-bayes" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/10/24/ML-practice-bayes/" class="article-date">
  	<time datetime="2016-10-24T13:40:18.000Z" itemprop="datePublished">2016-10-24</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      机器学习算法之朴素贝叶斯算法
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ML/">ML</a></li></ul>
	</div>

        

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <blockquote>
<p>以下是在学习《机器学习实战》时的一些记录</p>
</blockquote>
<h3 id="理论基础"><a href="#理论基础" class="headerlink" title="理论基础"></a>理论基础</h3><ul>
<li>朴素贝叶斯基于的两个理论基础<ul>
<li>贝叶斯决策理论，也就是说如果我们对于一个（x,y）有两个概率,p1(x,y),p2(x,y)，分别代表了(x,y)是属于第1类或是第2类的概率，如果我们有p1(x,y) &gt; p2(x,y)，那么我们就有信心将(x,y)归入到第1类中，反之就是归入第二类中</li>
<li>我们设定每个特征之间都是相互独立的，也就是说x,y之间没有任何关系，两个的取值没有影响; </li>
</ul>
</li>
</ul>
<a id="more"></a>
<ul>
<li><p>公式</p>
<ul>
<li><script type="math/tex; mode=display">p(c_i | \mathbf {w}) = {\frac {p(\mathbf{w}|c_i)p(c_i)}{p(\mathbf{w})}}</script></li>
<li><script type="math/tex; mode=display">p(\mathbf{w}|c_i) = p(w_0|c_i)*p(w_1|c_i)*...*p(w_n|c_i)</script></li>
<li>公式说明：第1个公式是求解的本质，表明两种数据条件概率之间的关系;第二个公式是根据每个特征都是相互独立得到的</li>
<li><p>套用到《机器学习实战》中的概念的话，$\mathbf {w}$ 表示词向量，它的长度是所有词的总数，每个元素位置代表了一个词，向量的元素值为1或为0,为1代表了文档中有这个词，否则代表无；$c_i$ 表示类型为i，$p(c_i | \mathbf {w})$表示在词向量为$\mathbf {w}$时，该文档为属于类型i的概率；$p(c_i)$表示了类型为i的文档概率，$p(\mathbf{w})$表示这个词向量的概率；$p(\mathbf{w}|c_i)$表示在类型为i的情况下，这个词向量的概率，根据第二条公式，因为假设了词与词之间都是相互独立的，所以其计算可以根据第二条公式来计算，而每个$p(w_j|c_i)$的计算可以根据已经有的数据来计算，也就是$w_j$这个词在所有类型为i的输入文档的词总数中占的比例；比方说有三个输入文档，第一个文档是类型1,有4个词，第二个是类型2,有5个词，第三个是类型1,有6个词，要计算词<code>sam</code>的在类型1的概率，已知它在词向量的位置为1,也就是$w_1$,它在3个文档中各出现1次，所以就在$p(w_1|c_1) = (1+1) / (4+6)$</p>
</li>
<li><p>另外还要补充一个对数公式：log(MN) = logM + logN</p>
</li>
</ul>
</li>
<li>代码说明<ul>
<li>代码<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 参数trainMatrix是一个文档集矩阵，矩阵中的每一行是一个词向量，代表了一个文档；trainCategory对应于trainMatrix的类型数组，表示每个文档的类型，为0或为1；</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">trainNB0</span><span class="params">(trainMatrix,trainCategory)</span>:</span></span><br><span class="line">  numTrainDocs = len(trainMatrix) <span class="comment">#求出文档集中文档的数目</span></span><br><span class="line">  numWords = len(trainMatrix[<span class="number">0</span>])  <span class="comment">#求出词向量的大小</span></span><br><span class="line">  pAbusive = sum(trainCategory)/float(numTrainDocs) <span class="comment">#算出类型为1的概率，也就是p(c_1),那么p(c_0) = 1 - p(c_1)</span></span><br><span class="line">  p0Num = zeros(numWords); p1Num = zeros(numWords)      <span class="comment">#p0Num，p1Num是两个与词向量等长的向量，p0Num用于记录在文档类型为0的情况下，所有输入文档中每个词出现的次数，比如假设一共有6种词(a,brother,cat,mother, son, you)分别对应于词向量的0到5的位置，则p0Num的形式类似[4,0,1,2,0,2]表示在所有类型为1的文档中，6种词出现的次数分别为4,0,1,2,0,2,也就是说a出现了4次，brother一次也没有；p1Num也是相同意思，只是是在所有类型为1的情况下</span></span><br><span class="line">  p0Denom = <span class="number">0.0</span>; p1Denom = <span class="number">0.0</span>                        <span class="comment">#p0Denom用于记录类型为0时，所有输入文档的词的总量，也就是在计算概率p(wi|c0)时的分母了</span></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> range(numTrainDocs):  <span class="comment">#遍历所有的输入文档</span></span><br><span class="line">      <span class="keyword">if</span> trainCategory[i] == <span class="number">1</span>:  <span class="comment">#对文档类型分类处理，如果是类型1的话如下处理</span></span><br><span class="line">          p1Num += trainMatrix[i] <span class="comment">#注意这里是向量相加，也就是对应位置相加，用途是计算所有类型为1的输入文档溃每个词的出现次数；</span></span><br><span class="line">          p1Denom += sum(trainMatrix[i]) <span class="comment">#将这次遍历到的类型为1的文档的词总数加入到p1Denom中，以累积求出所有的输入文档类型为1的词总数</span></span><br><span class="line">      <span class="keyword">else</span>:</span><br><span class="line">          p0Num += trainMatrix[i]</span><br><span class="line">          p0Denom += sum(trainMatrix[i])</span><br><span class="line">  p1Vect = p1Num/p1Denom          <span class="comment">#注意 这里也是向量与标量相除，是将每个向量的元素去除以标量，最后会得到一个向量，向量中的位置为i的元素数对应于p(wi | c1)，表示在类型为1的情况下，wi这个词出现的概率</span></span><br><span class="line">  p0Vect = p0Num/p0Denom          </span><br><span class="line">  <span class="keyword">return</span> p0Vect,p1Vect,pAbusive</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<ul>
<li>根据实际情况修改分类器<ul>
<li>考虑到公式2,我们要计算$p(\mathbf {w}|c_i)$时，需要进行乘法，如果有一个$p(w_j|c_i)$为0的话，那么整个就为0,所以我们给每个类别的情况下每个词都预置1次，那么也就是将初始化时<code>p0Num = zeros(numWords); p1Num = zeros(numWords)</code>改为<code>p0Num = ones(numWords); p1Num = ones(numWords)</code>同时将总的词数设为<code>p0Denom = 2.0; p1Denom = 2.0</code></li>
<li>因为词向量可能很大，总的词数也会很大，而某些词的出现次数可能很小，就会导致一个太多很小的数相乘的情况(概率相乘)，导致下溢出，得不到正确的答案；所以这里用对数的知识，对乘积取对数（因为对数是递增函数，不会影响我们对最终结果概率的大小的比较），有$log(p(\mathbf {w}|c_i) * p(c_i)) = log(p(\mathbf {w}|c_i)) + log(p(c_i)) = log(w_0|c_i) + log(w_1|ci) + … + log(w_n|c_i) + log(p(c_i))$ 所以我们在分类函数中<ul>
<li>代码<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">classifyNB</span><span class="params">(vec2Classify, p0Vec, p1Vec, pClass1)</span>:</span></span><br><span class="line">    p1 = sum(vec2Classify * log(p1Vec)) + log(pClass1)    <span class="comment">#这个就是上面推导出来的公式的直接应用了，记住在sum里面的计算的是向量的点乘，也就是相应位置相乘而心，因为vec2Classfy这个词向量里面已经记录了当前这个文档每个词的出现次数了，那用每个词的次数去乘以每个词对应概率的对数，再相加(上面的推导公式)就可以得到这个文档在类别1下的概率了</span></span><br><span class="line">    p0 = sum(vec2Classify * log(p0Vec)) + log(<span class="number">1.0</span> - pClass1)</span><br><span class="line">    <span class="keyword">if</span> p1 &gt; p0: <span class="comment">#应用贝叶斯决策</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>: </span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li>整体代码<ul>
<li><a href="">github</a></li>
</ul>
</li>
</ul>

      
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2016/10/25/CG-python-env-install/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption"><</strong>
      <div class="article-nav-title">
        
          python下包的安装
        
      </div>
    </a>
  
  
    <a href="/2016/10/24/ML-caffe-learning/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">《21天实战Caffe》记录</div>
      <strong class="article-nav-caption">></strong>
    </a>
  
</nav>

  
</article>


<div class="share_jia">
	<!-- JiaThis Button BEGIN -->
	<div class="jiathis_style">
		<span class="jiathis_txt">分享到: &nbsp; </span>
		<a class="jiathis_button_facebook"></a> 
    <a class="jiathis_button_twitter"></a>
    <a class="jiathis_button_plus"></a> 
    <a class="jiathis_button_tsina"></a>
		<a class="jiathis_button_cqq"></a>
		<a class="jiathis_button_douban"></a>
		<a class="jiathis_button_weixin"></a>
		<a class="jiathis_button_tumblr"></a>
    <a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	</div>
	<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=1405949716054953" charset="utf-8"></script>
	<!-- JiaThis Button END -->
</div>






<div class="duoshuo">
	<!-- 多说评论框 start -->
	<div class="ds-thread" data-thread-key="ML-practice-bayes" data-title="机器学习算法之朴素贝叶斯算法" data-url="https://sysukinthon.github.io/2016/10/24/ML-practice-bayes/"></div>
	<!-- 多说评论框 end -->
	<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"true"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
	<!-- 多说公共JS代码 end -->
</div>




</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2016 Kinthon
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: true,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="https://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js" type="text/javascript"></script>
<script src="/js/main.js" type="text/javascript"></script>






<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  </div><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
</body>
</html>